## Abstract

In this paper, we study the effect of introducing noise to a question- answering dataset using a Masked Language Model frame- work. 
Our aim is to inspect the degree to which the model shows human-like behaviour when comprehending common natural language understanding tasks. 
In particular, we’re in- terested in the model’s ability to utilize high level information, such as syntactical structure, to make predictions in the task. 
In order to investigate the model’s sensitivity to the syntax and structure of language, we intentionally injected noise to both specific parts of 
speech and distinct positions within a sen- tence. Our results show that model performance was mostly a function of the position and quantity of noise. 
Noise intro- duced randomly at the end of the sentence and with a higher probability, had more of an effect on model performance than when it was 
targeted to a specific part of speech.
